{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_image_size = 1000\n",
    "hr_size = 100\n",
    "lr_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_image_to_parts(img, hr_size, big_image_size):\n",
    "    r_image = cv2.resize(img, (big_image_size, big_image_size))\n",
    "    height, width, channel = r_image.shape\n",
    "    CROP_H_SIZE = big_image_size // hr_size\n",
    "    CROP_W_SIZE = big_image_size // hr_size\n",
    "    images = []\n",
    "    for ih in range(CROP_H_SIZE):\n",
    "        for iw in range(CROP_W_SIZE):\n",
    "            x = width // CROP_W_SIZE * iw\n",
    "            y = height // CROP_H_SIZE * ih\n",
    "            h = (height // CROP_H_SIZE)\n",
    "            w = (width // CROP_W_SIZE)\n",
    "            images.append(r_image[y:y + h, x:x + w])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/super-resolution-pics/pics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-071ff09ec5da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/super-resolution-pics/pics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfile_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/super-resolution-pics/pics/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpic_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/super-resolution-pics/pics'"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "file_index = 1\n",
    "for file in os.listdir(\"/kaggle/input/super-resolution-pics/pics\"):\n",
    "    file_image = cv2.imread(\"/kaggle/input/super-resolution-pics/pics/\" + file, cv2.IMREAD_COLOR)\n",
    "    pic_index = 1\n",
    "    small_images = big_image_to_parts(file_image, hr_size, big_image_size)\n",
    "    for img in small_images:\n",
    "        pic_name = \"/kaggle/input_images/y/\" + str(file_index) + \"_\" + str(pic_index) + \".jpg\"\n",
    "        y.append(img)\n",
    "        cv2.imwrite(pic_name, img)\n",
    "        img_scale_down = cv2.resize(img, (lr_size, lr_size))\n",
    "        image2 = cv2.resize(img_scale_down, (hr_size, hr_size), interpolation=cv2.INTER_LINEAR)\n",
    "        X.append(image2)\n",
    "        pic_name = \"/kaggle/input_images/X/\" + str(file_index) + \"_\" + str(pic_index) + \".jpg\"\n",
    "        cv2.imwrite(pic_name, image2)\n",
    "        pic_index += 1\n",
    "    file_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "input = layers.Input(shape=(hr_size, hr_size, 3))\n",
    "x = layers.Conv2D(32, (9, 9), padding=\"same\", activation=\"relu\", name=\"level1\")(input)\n",
    "x = layers.Conv2D(32, (5, 5), padding='same', activation=\"relu\", name=\"level2\")(x)\n",
    "out = layers.Conv2D(3, (3, 3), padding='same', activation=\"relu\", name=\"out\")(x)\n",
    "\n",
    "model = keras.Model(input, out)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "X /= 255.0\n",
    "y = y.astype('float32')\n",
    "y /= 255.0\n",
    "X.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 9s 1ms/sample - loss: 0.0039 - acc: 0.8322 - val_loss: 0.0017 - val_acc: 0.8616\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 7s 905us/sample - loss: 0.0020 - acc: 0.8763 - val_loss: 0.0015 - val_acc: 0.8906\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 7s 898us/sample - loss: 0.0019 - acc: 0.8981 - val_loss: 0.0015 - val_acc: 0.8217\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 7s 921us/sample - loss: 0.0018 - acc: 0.8901 - val_loss: 0.0014 - val_acc: 0.9012\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 7s 895us/sample - loss: 0.0018 - acc: 0.8946 - val_loss: 0.0014 - val_acc: 0.8676\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0024 - acc: 0.8784 - val_loss: 0.0015 - val_acc: 0.8820\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 7s 888us/sample - loss: 0.0018 - acc: 0.8977 - val_loss: 0.0015 - val_acc: 0.9010\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 7s 888us/sample - loss: 0.0018 - acc: 0.8987 - val_loss: 0.0014 - val_acc: 0.9294\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 7s 887us/sample - loss: 0.0016 - acc: 0.9114 - val_loss: 0.0015 - val_acc: 0.8691\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0017 - acc: 0.9049 - val_loss: 0.0014 - val_acc: 0.9309\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 7s 896us/sample - loss: 0.0018 - acc: 0.8994 - val_loss: 0.0014 - val_acc: 0.9027\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 7s 893us/sample - loss: 0.0016 - acc: 0.9126 - val_loss: 0.0014 - val_acc: 0.9412\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0016 - acc: 0.9185 - val_loss: 0.0014 - val_acc: 0.9051\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 7s 887us/sample - loss: 0.0017 - acc: 0.9045 - val_loss: 0.0014 - val_acc: 0.9049\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 7s 884us/sample - loss: 0.0017 - acc: 0.9048 - val_loss: 0.0015 - val_acc: 0.8566\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 7s 897us/sample - loss: 0.0016 - acc: 0.9155 - val_loss: 0.0014 - val_acc: 0.9363\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0016 - acc: 0.9204 - val_loss: 0.0014 - val_acc: 0.9358\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0016 - acc: 0.9171 - val_loss: 0.0032 - val_acc: 0.5160\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 7s 894us/sample - loss: 0.0016 - acc: 0.9102 - val_loss: 0.0014 - val_acc: 0.8950\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0015 - acc: 0.9260 - val_loss: 0.0014 - val_acc: 0.9413\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0016 - acc: 0.9181 - val_loss: 0.0014 - val_acc: 0.9229\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 7s 897us/sample - loss: 0.0016 - acc: 0.9092 - val_loss: 0.0015 - val_acc: 0.8737\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 7s 895us/sample - loss: 0.0015 - acc: 0.9270 - val_loss: 0.0013 - val_acc: 0.9219\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0015 - acc: 0.9170 - val_loss: 0.0014 - val_acc: 0.9002\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 7s 901us/sample - loss: 0.0015 - acc: 0.9164 - val_loss: 0.0013 - val_acc: 0.9410\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 7s 882us/sample - loss: 0.0015 - acc: 0.9224 - val_loss: 0.0014 - val_acc: 0.9355\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 7s 883us/sample - loss: 0.0016 - acc: 0.9161 - val_loss: 0.0016 - val_acc: 0.8423\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0015 - acc: 0.9218 - val_loss: 0.0014 - val_acc: 0.9271\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0015 - acc: 0.9183 - val_loss: 0.0014 - val_acc: 0.8627\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 7s 897us/sample - loss: 0.0015 - acc: 0.9209 - val_loss: 0.0013 - val_acc: 0.9310\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 7s 891us/sample - loss: 0.0015 - acc: 0.9274 - val_loss: 0.0013 - val_acc: 0.8989\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0015 - acc: 0.9217 - val_loss: 0.0013 - val_acc: 0.9034\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 7s 897us/sample - loss: 0.0015 - acc: 0.9222 - val_loss: 0.0015 - val_acc: 0.7993\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 7s 887us/sample - loss: 0.0016 - acc: 0.9204 - val_loss: 0.0013 - val_acc: 0.9066\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 7s 886us/sample - loss: 0.0017 - acc: 0.9085 - val_loss: 0.0014 - val_acc: 0.8981\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 7s 891us/sample - loss: 0.0015 - acc: 0.9237 - val_loss: 0.0013 - val_acc: 0.9092\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 7s 895us/sample - loss: 0.0015 - acc: 0.9217 - val_loss: 0.0014 - val_acc: 0.9317\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0015 - acc: 0.9226 - val_loss: 0.0013 - val_acc: 0.9423\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 7s 931us/sample - loss: 0.0015 - acc: 0.9288 - val_loss: 0.0015 - val_acc: 0.8145\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0016 - acc: 0.9184 - val_loss: 0.0013 - val_acc: 0.9069\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 7s 895us/sample - loss: 0.0016 - acc: 0.9120 - val_loss: 0.0017 - val_acc: 0.6807\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0019 - acc: 0.9127 - val_loss: 0.0015 - val_acc: 0.9158\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 7s 886us/sample - loss: 0.0016 - acc: 0.9168 - val_loss: 0.0014 - val_acc: 0.8915\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 7s 914us/sample - loss: 0.0017 - acc: 0.9070 - val_loss: 0.0014 - val_acc: 0.9338\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 7s 904us/sample - loss: 0.0016 - acc: 0.9104 - val_loss: 0.0014 - val_acc: 0.8638\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 7s 895us/sample - loss: 0.0016 - acc: 0.9139 - val_loss: 0.0014 - val_acc: 0.9008\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 7s 891us/sample - loss: 0.0016 - acc: 0.9135 - val_loss: 0.0016 - val_acc: 0.7963\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 7s 886us/sample - loss: 0.0015 - acc: 0.9201 - val_loss: 0.0013 - val_acc: 0.9061\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 7s 893us/sample - loss: 0.0015 - acc: 0.9211 - val_loss: 0.0013 - val_acc: 0.9290\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 7s 891us/sample - loss: 0.0015 - acc: 0.9136 - val_loss: 0.0013 - val_acc: 0.9202\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0015 - acc: 0.9169 - val_loss: 0.0013 - val_acc: 0.9077\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 7s 891us/sample - loss: 0.0015 - acc: 0.9190 - val_loss: 0.0013 - val_acc: 0.9154\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 7s 894us/sample - loss: 0.0015 - acc: 0.9244 - val_loss: 0.0014 - val_acc: 0.8971\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 7s 888us/sample - loss: 0.0015 - acc: 0.9144 - val_loss: 0.0013 - val_acc: 0.9456\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0015 - acc: 0.9216 - val_loss: 0.0013 - val_acc: 0.9279\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 7s 896us/sample - loss: 0.0015 - acc: 0.9251 - val_loss: 0.0013 - val_acc: 0.9351\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 7s 897us/sample - loss: 0.0015 - acc: 0.9174 - val_loss: 0.0014 - val_acc: 0.9044\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 7s 879us/sample - loss: 0.0015 - acc: 0.9207 - val_loss: 0.0013 - val_acc: 0.9389\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 7s 893us/sample - loss: 0.0015 - acc: 0.9271 - val_loss: 0.0014 - val_acc: 0.9407\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0015 - acc: 0.9213 - val_loss: 0.0016 - val_acc: 0.8633\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 7s 891us/sample - loss: 0.0015 - acc: 0.9252 - val_loss: 0.0017 - val_acc: 0.7757\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 7s 908us/sample - loss: 0.0015 - acc: 0.9163 - val_loss: 0.0019 - val_acc: 0.9217\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0015 - acc: 0.9225 - val_loss: 0.0013 - val_acc: 0.9098\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0015 - acc: 0.9226 - val_loss: 0.0013 - val_acc: 0.9163\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 7s 894us/sample - loss: 0.0015 - acc: 0.9269 - val_loss: 0.0014 - val_acc: 0.8905\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 7s 887us/sample - loss: 0.0015 - acc: 0.9200 - val_loss: 0.0013 - val_acc: 0.9432\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0015 - acc: 0.9206 - val_loss: 0.0013 - val_acc: 0.9371\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 7s 894us/sample - loss: 0.0015 - acc: 0.9211 - val_loss: 0.0013 - val_acc: 0.9446\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 7s 888us/sample - loss: 0.0015 - acc: 0.9239 - val_loss: 0.0013 - val_acc: 0.9455\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 7s 903us/sample - loss: 0.0015 - acc: 0.9282 - val_loss: 0.0013 - val_acc: 0.9413\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0015 - acc: 0.9226 - val_loss: 0.0013 - val_acc: 0.9044\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0015 - acc: 0.9187 - val_loss: 0.0013 - val_acc: 0.9390\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 7s 882us/sample - loss: 0.0015 - acc: 0.9237 - val_loss: 0.0013 - val_acc: 0.8962\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 7s 893us/sample - loss: 0.0015 - acc: 0.9295 - val_loss: 0.0018 - val_acc: 0.7392\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 7s 887us/sample - loss: 0.0015 - acc: 0.9259 - val_loss: 0.0014 - val_acc: 0.8417\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0015 - acc: 0.9251 - val_loss: 0.0013 - val_acc: 0.9281\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 7s 885us/sample - loss: 0.0015 - acc: 0.9291 - val_loss: 0.0014 - val_acc: 0.8618\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 7s 897us/sample - loss: 0.0015 - acc: 0.9243 - val_loss: 0.0013 - val_acc: 0.8956\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 7s 901us/sample - loss: 0.0015 - acc: 0.9239 - val_loss: 0.0013 - val_acc: 0.9088\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 7s 891us/sample - loss: 0.0015 - acc: 0.9311 - val_loss: 0.0013 - val_acc: 0.9089\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 7s 937us/sample - loss: 0.0015 - acc: 0.9201 - val_loss: 0.0013 - val_acc: 0.9094\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 7s 899us/sample - loss: 0.0015 - acc: 0.9240 - val_loss: 0.0013 - val_acc: 0.9428\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0014 - acc: 0.9268 - val_loss: 0.0013 - val_acc: 0.9050\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 7s 888us/sample - loss: 0.0015 - acc: 0.9239 - val_loss: 0.0013 - val_acc: 0.9436\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 7s 895us/sample - loss: 0.0015 - acc: 0.9240 - val_loss: 0.0013 - val_acc: 0.8982\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 7s 898us/sample - loss: 0.0015 - acc: 0.9273 - val_loss: 0.0014 - val_acc: 0.9412\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 7s 901us/sample - loss: 0.0015 - acc: 0.9195 - val_loss: 0.0013 - val_acc: 0.9061\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 7s 906us/sample - loss: 0.0015 - acc: 0.9251 - val_loss: 0.0013 - val_acc: 0.9121\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 7s 899us/sample - loss: 0.0014 - acc: 0.9276 - val_loss: 0.0013 - val_acc: 0.9060\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 7s 889us/sample - loss: 0.0015 - acc: 0.9208 - val_loss: 0.0013 - val_acc: 0.9067\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0014 - acc: 0.9275 - val_loss: 0.0013 - val_acc: 0.9384\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 7s 890us/sample - loss: 0.0016 - acc: 0.9216 - val_loss: 0.0013 - val_acc: 0.9282\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 7s 888us/sample - loss: 0.0015 - acc: 0.9311 - val_loss: 0.0013 - val_acc: 0.9110\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 7s 891us/sample - loss: 0.0015 - acc: 0.9236 - val_loss: 0.0013 - val_acc: 0.8939\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 7s 893us/sample - loss: 0.0015 - acc: 0.9227 - val_loss: 0.0013 - val_acc: 0.9319\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 7s 896us/sample - loss: 0.0015 - acc: 0.9276 - val_loss: 0.0013 - val_acc: 0.9114\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 7s 900us/sample - loss: 0.0014 - acc: 0.9323 - val_loss: 0.0013 - val_acc: 0.9023\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 7s 892us/sample - loss: 0.0015 - acc: 0.9135 - val_loss: 0.0013 - val_acc: 0.9342\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 7s 886us/sample - loss: 0.0015 - acc: 0.9322 - val_loss: 0.0013 - val_acc: 0.9082\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 7s 894us/sample - loss: 0.0015 - acc: 0.9237 - val_loss: 0.0013 - val_acc: 0.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd6a1a11160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, validation_split = 0.2, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='model.h5' target='_blank'>model.h5</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/model.h5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
